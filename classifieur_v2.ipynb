{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72b5695",
   "metadata": {},
   "source": [
    "# Construction du classifieur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbfb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from skimage import io, util\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "# Ah stylé d'avoir trouvé ça !\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import ORB\n",
    "from skimage.feature import SIFT\n",
    "from skimage.feature import daisy\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e83910",
   "metadata": {},
   "source": [
    "## Récupération des jeux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4782121",
   "metadata": {},
   "source": [
    "## Découper les écocups et les négatifs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f6a18",
   "metadata": {},
   "source": [
    "On découpe les positifs en fonction de bbox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356c3fc",
   "metadata": {},
   "source": [
    "On va découper des bouts d'images négatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a90eb",
   "metadata": {},
   "source": [
    "## Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11714c0",
   "metadata": {},
   "source": [
    "Supprimer les images vides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e001b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "pos_patch_fs = [f for f in  os.listdir(os.path.join(\"local_data\", \"4_normalized_patches\", \"pos\")) if f.endswith(\".jpg\")]\n",
    "neg_patch_fs = [f for f in  os.listdir(os.path.join(\"local_data\", \"4_normalized_patches\", \"neg\")) if f.endswith(\".jpg\")]\n",
    "\n",
    "pos_patchs = []\n",
    "neg_patchs = []\n",
    "\n",
    "for f in pos_patch_fs:\n",
    "    try:\n",
    "        patch = plt.imread(\n",
    "            os.path.join(\"local_data\", \"4_normalized_patches\", \"pos\", f)\n",
    "        )\n",
    "        pos_patchs.append(patch[:,:,0]) # le channel grayscale est dupliqué sur les 3 chanaux RGB (on en isole 1)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "for f in neg_patch_fs:\n",
    "    try:\n",
    "        patch = plt.imread(\n",
    "            os.path.join(\"local_data\", \"4_normalized_patches\", \"neg\", f)\n",
    "        )\n",
    "        neg_patchs.append(patch[:,:,0]) # le channel grayscale est dupliqué sur les 3 chanaux RGB (on en isole 1)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a07fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204\n",
      "6020\n",
      "(128, 72)\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_patchs))\n",
    "print(len(neg_patchs))\n",
    "\n",
    "print(pos_patchs[0].shape) # on est bien en grayscale\n",
    "\n",
    "nb_patchs_tot = len(pos_patchs) + len(neg_patchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d77e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7224\n",
      "5779\n",
      "1445\n"
     ]
    }
   ],
   "source": [
    "train_part = 80 / 100\n",
    "train_size = int(nb_patchs_tot * train_part)\n",
    "\n",
    "# Mélange des indices, pour que les données soient mélangées \"en même temps\" que les classes vérités\n",
    "indices = np.arange(nb_patchs_tot)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Fabrication des classes : 1 : positif, 0 : négatif\n",
    "y = []\n",
    "for _ in range(len(pos_patchs)):\n",
    "    y.append(1)\n",
    "\n",
    "for _ in range(len(neg_patchs)):\n",
    "    y.append(0)\n",
    "y_shuffled = np.array(y)[indices]\n",
    "y_train = y_shuffled[0:train_size]\n",
    "y_test = y_shuffled[train_size:]\n",
    "\n",
    "print(len(y_shuffled))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c067ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7224, 128, 72)\n"
     ]
    }
   ],
   "source": [
    "patchs = np.array(pos_patchs + neg_patchs)\n",
    "print(patchs.shape)\n",
    "\n",
    "def get_X_train_and_test_for_extractor(extractor):\n",
    "        \n",
    "    X = extractor(patchs)\n",
    "    # print(X.shape)\n",
    "    \n",
    "    X_shuffled = X[indices]\n",
    "    X_train = X_shuffled[0:train_size]\n",
    "    X_test = X_shuffled[train_size:]\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69e4e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5779, 7938)\n",
      "(1445, 7938)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "def HOG_extractor(patchs):\n",
    "    first_features = hog(patchs[0]) # valeurs par défaut\n",
    "    features = np.zeros(shape=(len(patchs),first_features.shape[0]), dtype=first_features.dtype)\n",
    "    for i, patch in enumerate(patchs):\n",
    "        features[i] = hog(patch)\n",
    "\n",
    "    return features\n",
    "\n",
    "X_train_HOG, X_test_HOG = get_X_train_and_test_for_extractor(HOG_extractor)\n",
    "\n",
    "print(X_train_HOG.shape)\n",
    "print(X_test_HOG.shape)\n",
    "print(X_train_HOG.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b16fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, aucun descripteur trouvé pour i = 74\n",
      "Warning, aucun descripteur trouvé pour i = 75\n",
      "Warning, aucun descripteur trouvé pour i = 168\n",
      "Warning, aucun descripteur trouvé pour i = 169\n",
      "Warning, aucun descripteur trouvé pour i = 170\n",
      "Warning, aucun descripteur trouvé pour i = 171\n",
      "Warning, aucun descripteur trouvé pour i = 221\n",
      "Warning, aucun descripteur trouvé pour i = 222\n",
      "Warning, aucun descripteur trouvé pour i = 223\n",
      "Warning, aucun descripteur trouvé pour i = 274\n",
      "Warning, aucun descripteur trouvé pour i = 275\n",
      "Warning, aucun descripteur trouvé pour i = 560\n",
      "Warning, aucun descripteur trouvé pour i = 561\n",
      "Warning, aucun descripteur trouvé pour i = 562\n",
      "Warning, aucun descripteur trouvé pour i = 563\n",
      "Warning, aucun descripteur trouvé pour i = 972\n",
      "Warning, aucun descripteur trouvé pour i = 973\n",
      "Warning, aucun descripteur trouvé pour i = 974\n",
      "Warning, aucun descripteur trouvé pour i = 975\n",
      "Warning, aucun descripteur trouvé pour i = 1192\n",
      "Warning, aucun descripteur trouvé pour i = 1193\n",
      "Warning, aucun descripteur trouvé pour i = 1194\n",
      "Warning, aucun descripteur trouvé pour i = 1195\n",
      "Warning, aucun descripteur trouvé pour i = 1312\n",
      "Warning, aucun descripteur trouvé pour i = 1313\n",
      "Warning, aucun descripteur trouvé pour i = 1314\n",
      "Warning, aucun descripteur trouvé pour i = 1315\n",
      "Warning, aucun descripteur trouvé pour i = 1316\n",
      "Warning, aucun descripteur trouvé pour i = 1317\n",
      "Warning, aucun descripteur trouvé pour i = 1318\n",
      "Warning, aucun descripteur trouvé pour i = 1319\n",
      "Warning, aucun descripteur trouvé pour i = 1340\n",
      "Warning, aucun descripteur trouvé pour i = 1341\n",
      "Warning, aucun descripteur trouvé pour i = 1342\n",
      "Warning, aucun descripteur trouvé pour i = 1343\n",
      "Warning, aucun descripteur trouvé pour i = 1476\n",
      "Warning, aucun descripteur trouvé pour i = 1477\n",
      "Warning, aucun descripteur trouvé pour i = 1478\n",
      "Warning, aucun descripteur trouvé pour i = 1479\n",
      "Warning, aucun descripteur trouvé pour i = 1480\n",
      "Warning, aucun descripteur trouvé pour i = 1481\n",
      "Warning, aucun descripteur trouvé pour i = 1482\n",
      "Warning, aucun descripteur trouvé pour i = 1483\n",
      "Warning, aucun descripteur trouvé pour i = 1536\n",
      "Warning, aucun descripteur trouvé pour i = 1537\n",
      "Warning, aucun descripteur trouvé pour i = 1538\n",
      "Warning, aucun descripteur trouvé pour i = 1539\n",
      "Warning, aucun descripteur trouvé pour i = 1585\n",
      "Warning, aucun descripteur trouvé pour i = 1587\n",
      "Warning, aucun descripteur trouvé pour i = 1864\n",
      "Warning, aucun descripteur trouvé pour i = 1865\n",
      "Warning, aucun descripteur trouvé pour i = 1866\n",
      "Warning, aucun descripteur trouvé pour i = 1867\n",
      "Warning, aucun descripteur trouvé pour i = 2183\n",
      "Warning, aucun descripteur trouvé pour i = 2184\n",
      "Warning, aucun descripteur trouvé pour i = 2185\n",
      "Warning, aucun descripteur trouvé pour i = 2186\n",
      "Warning, aucun descripteur trouvé pour i = 2187\n",
      "Warning, aucun descripteur trouvé pour i = 2509\n",
      "Warning, aucun descripteur trouvé pour i = 2510\n",
      "Warning, aucun descripteur trouvé pour i = 2511\n",
      "Warning, aucun descripteur trouvé pour i = 2552\n",
      "Warning, aucun descripteur trouvé pour i = 2553\n",
      "Warning, aucun descripteur trouvé pour i = 2554\n",
      "Warning, aucun descripteur trouvé pour i = 2555\n",
      "Warning, aucun descripteur trouvé pour i = 2580\n",
      "Warning, aucun descripteur trouvé pour i = 2583\n",
      "Warning, aucun descripteur trouvé pour i = 2608\n",
      "Warning, aucun descripteur trouvé pour i = 2609\n",
      "Warning, aucun descripteur trouvé pour i = 2610\n",
      "Warning, aucun descripteur trouvé pour i = 2616\n",
      "Warning, aucun descripteur trouvé pour i = 2617\n",
      "Warning, aucun descripteur trouvé pour i = 2618\n",
      "Warning, aucun descripteur trouvé pour i = 2619\n",
      "Warning, aucun descripteur trouvé pour i = 2740\n",
      "Warning, aucun descripteur trouvé pour i = 2741\n",
      "Warning, aucun descripteur trouvé pour i = 2742\n",
      "Warning, aucun descripteur trouvé pour i = 2743\n",
      "Warning, aucun descripteur trouvé pour i = 2794\n",
      "Warning, aucun descripteur trouvé pour i = 2795\n",
      "Warning, aucun descripteur trouvé pour i = 2804\n",
      "Warning, aucun descripteur trouvé pour i = 2805\n",
      "Warning, aucun descripteur trouvé pour i = 2806\n",
      "Warning, aucun descripteur trouvé pour i = 2807\n",
      "Warning, aucun descripteur trouvé pour i = 2885\n",
      "Warning, aucun descripteur trouvé pour i = 2887\n",
      "Warning, aucun descripteur trouvé pour i = 2908\n",
      "Warning, aucun descripteur trouvé pour i = 2909\n",
      "Warning, aucun descripteur trouvé pour i = 2910\n",
      "Warning, aucun descripteur trouvé pour i = 2911\n",
      "Warning, aucun descripteur trouvé pour i = 2996\n",
      "Warning, aucun descripteur trouvé pour i = 2997\n",
      "Warning, aucun descripteur trouvé pour i = 2998\n",
      "Warning, aucun descripteur trouvé pour i = 2999\n",
      "Warning, aucun descripteur trouvé pour i = 3025\n",
      "Warning, aucun descripteur trouvé pour i = 3026\n",
      "Warning, aucun descripteur trouvé pour i = 3027\n",
      "Warning, aucun descripteur trouvé pour i = 3052\n",
      "Warning, aucun descripteur trouvé pour i = 3053\n",
      "Warning, aucun descripteur trouvé pour i = 3157\n",
      "Warning, aucun descripteur trouvé pour i = 3158\n",
      "Warning, aucun descripteur trouvé pour i = 3159\n",
      "Warning, aucun descripteur trouvé pour i = 3390\n",
      "Warning, aucun descripteur trouvé pour i = 3391\n",
      "Warning, aucun descripteur trouvé pour i = 3425\n",
      "Warning, aucun descripteur trouvé pour i = 3427\n",
      "Warning, aucun descripteur trouvé pour i = 3444\n",
      "Warning, aucun descripteur trouvé pour i = 3445\n",
      "Warning, aucun descripteur trouvé pour i = 3478\n",
      "Warning, aucun descripteur trouvé pour i = 3479\n",
      "Warning, aucun descripteur trouvé pour i = 3764\n",
      "Warning, aucun descripteur trouvé pour i = 3765\n",
      "Warning, aucun descripteur trouvé pour i = 3766\n",
      "Warning, aucun descripteur trouvé pour i = 3767\n",
      "Warning, aucun descripteur trouvé pour i = 3768\n",
      "Warning, aucun descripteur trouvé pour i = 3769\n",
      "Warning, aucun descripteur trouvé pour i = 3770\n",
      "Warning, aucun descripteur trouvé pour i = 3771\n",
      "Warning, aucun descripteur trouvé pour i = 3772\n",
      "Warning, aucun descripteur trouvé pour i = 3773\n",
      "Warning, aucun descripteur trouvé pour i = 3774\n",
      "Warning, aucun descripteur trouvé pour i = 3775\n",
      "Warning, aucun descripteur trouvé pour i = 3880\n",
      "Warning, aucun descripteur trouvé pour i = 3881\n",
      "Warning, aucun descripteur trouvé pour i = 3882\n",
      "Warning, aucun descripteur trouvé pour i = 3883\n",
      "Warning, aucun descripteur trouvé pour i = 3917\n",
      "Warning, aucun descripteur trouvé pour i = 3918\n",
      "Warning, aucun descripteur trouvé pour i = 3919\n",
      "Warning, aucun descripteur trouvé pour i = 4068\n",
      "Warning, aucun descripteur trouvé pour i = 4069\n",
      "Warning, aucun descripteur trouvé pour i = 4117\n",
      "Warning, aucun descripteur trouvé pour i = 4119\n",
      "Warning, aucun descripteur trouvé pour i = 4175\n",
      "Warning, aucun descripteur trouvé pour i = 4176\n",
      "Warning, aucun descripteur trouvé pour i = 4177\n",
      "Warning, aucun descripteur trouvé pour i = 4178\n",
      "Warning, aucun descripteur trouvé pour i = 4179\n",
      "Warning, aucun descripteur trouvé pour i = 4392\n",
      "Warning, aucun descripteur trouvé pour i = 4393\n",
      "Warning, aucun descripteur trouvé pour i = 4394\n",
      "Warning, aucun descripteur trouvé pour i = 4395\n",
      "Warning, aucun descripteur trouvé pour i = 4604\n",
      "Warning, aucun descripteur trouvé pour i = 4605\n",
      "Warning, aucun descripteur trouvé pour i = 4606\n",
      "Warning, aucun descripteur trouvé pour i = 4607\n",
      "Warning, aucun descripteur trouvé pour i = 4622\n",
      "Warning, aucun descripteur trouvé pour i = 4640\n",
      "Warning, aucun descripteur trouvé pour i = 4641\n",
      "Warning, aucun descripteur trouvé pour i = 4642\n",
      "Warning, aucun descripteur trouvé pour i = 4712\n",
      "Warning, aucun descripteur trouvé pour i = 4713\n",
      "Warning, aucun descripteur trouvé pour i = 4714\n",
      "Warning, aucun descripteur trouvé pour i = 4715\n",
      "Warning, aucun descripteur trouvé pour i = 4761\n",
      "Warning, aucun descripteur trouvé pour i = 4820\n",
      "Warning, aucun descripteur trouvé pour i = 4821\n",
      "Warning, aucun descripteur trouvé pour i = 4822\n",
      "Warning, aucun descripteur trouvé pour i = 4823\n",
      "Warning, aucun descripteur trouvé pour i = 4892\n",
      "Warning, aucun descripteur trouvé pour i = 4893\n",
      "Warning, aucun descripteur trouvé pour i = 4894\n",
      "Warning, aucun descripteur trouvé pour i = 4895\n",
      "Warning, aucun descripteur trouvé pour i = 4920\n",
      "Warning, aucun descripteur trouvé pour i = 4921\n",
      "Warning, aucun descripteur trouvé pour i = 4922\n",
      "Warning, aucun descripteur trouvé pour i = 4923\n",
      "Warning, aucun descripteur trouvé pour i = 4944\n",
      "Warning, aucun descripteur trouvé pour i = 4945\n",
      "Warning, aucun descripteur trouvé pour i = 4946\n",
      "Warning, aucun descripteur trouvé pour i = 4947\n",
      "Warning, aucun descripteur trouvé pour i = 5268\n",
      "Warning, aucun descripteur trouvé pour i = 5269\n",
      "Warning, aucun descripteur trouvé pour i = 5270\n",
      "Warning, aucun descripteur trouvé pour i = 5271\n",
      "Warning, aucun descripteur trouvé pour i = 5284\n",
      "Warning, aucun descripteur trouvé pour i = 5285\n",
      "Warning, aucun descripteur trouvé pour i = 5286\n",
      "Warning, aucun descripteur trouvé pour i = 5287\n",
      "Warning, aucun descripteur trouvé pour i = 5288\n",
      "Warning, aucun descripteur trouvé pour i = 5290\n",
      "Warning, aucun descripteur trouvé pour i = 5396\n",
      "Warning, aucun descripteur trouvé pour i = 5397\n",
      "Warning, aucun descripteur trouvé pour i = 5398\n",
      "Warning, aucun descripteur trouvé pour i = 5399\n",
      "Warning, aucun descripteur trouvé pour i = 5444\n",
      "Warning, aucun descripteur trouvé pour i = 5445\n",
      "Warning, aucun descripteur trouvé pour i = 5446\n",
      "Warning, aucun descripteur trouvé pour i = 5447\n",
      "Warning, aucun descripteur trouvé pour i = 5448\n",
      "Warning, aucun descripteur trouvé pour i = 5449\n",
      "Warning, aucun descripteur trouvé pour i = 5450\n",
      "Warning, aucun descripteur trouvé pour i = 5451\n",
      "Warning, aucun descripteur trouvé pour i = 5624\n",
      "Warning, aucun descripteur trouvé pour i = 5625\n",
      "Warning, aucun descripteur trouvé pour i = 5626\n",
      "Warning, aucun descripteur trouvé pour i = 5668\n",
      "Warning, aucun descripteur trouvé pour i = 5669\n",
      "Warning, aucun descripteur trouvé pour i = 5670\n",
      "Warning, aucun descripteur trouvé pour i = 5671\n",
      "Warning, aucun descripteur trouvé pour i = 5746\n",
      "Warning, aucun descripteur trouvé pour i = 5747\n",
      "Warning, aucun descripteur trouvé pour i = 5785\n",
      "Warning, aucun descripteur trouvé pour i = 5787\n",
      "Warning, aucun descripteur trouvé pour i = 5796\n",
      "Warning, aucun descripteur trouvé pour i = 5797\n",
      "Warning, aucun descripteur trouvé pour i = 5798\n",
      "Warning, aucun descripteur trouvé pour i = 5799\n",
      "Warning, aucun descripteur trouvé pour i = 5828\n",
      "Warning, aucun descripteur trouvé pour i = 5829\n",
      "Warning, aucun descripteur trouvé pour i = 5830\n",
      "Warning, aucun descripteur trouvé pour i = 5831\n",
      "Warning, aucun descripteur trouvé pour i = 5848\n",
      "Warning, aucun descripteur trouvé pour i = 5849\n",
      "Warning, aucun descripteur trouvé pour i = 5850\n",
      "Warning, aucun descripteur trouvé pour i = 5851\n",
      "Warning, aucun descripteur trouvé pour i = 5865\n",
      "Warning, aucun descripteur trouvé pour i = 5866\n",
      "Warning, aucun descripteur trouvé pour i = 5867\n",
      "Warning, aucun descripteur trouvé pour i = 5949\n",
      "Warning, aucun descripteur trouvé pour i = 5950\n",
      "Warning, aucun descripteur trouvé pour i = 5951\n",
      "Warning, aucun descripteur trouvé pour i = 5956\n",
      "Warning, aucun descripteur trouvé pour i = 5957\n",
      "Warning, aucun descripteur trouvé pour i = 5958\n",
      "Warning, aucun descripteur trouvé pour i = 5959\n",
      "Warning, aucun descripteur trouvé pour i = 5998\n",
      "Warning, aucun descripteur trouvé pour i = 5999\n",
      "Warning, aucun descripteur trouvé pour i = 6000\n",
      "Warning, aucun descripteur trouvé pour i = 6001\n",
      "Warning, aucun descripteur trouvé pour i = 6002\n",
      "Warning, aucun descripteur trouvé pour i = 6003\n",
      "Warning, aucun descripteur trouvé pour i = 6004\n",
      "Warning, aucun descripteur trouvé pour i = 6005\n",
      "Warning, aucun descripteur trouvé pour i = 6006\n",
      "Warning, aucun descripteur trouvé pour i = 6007\n",
      "Warning, aucun descripteur trouvé pour i = 6166\n",
      "Warning, aucun descripteur trouvé pour i = 6167\n",
      "Warning, aucun descripteur trouvé pour i = 6168\n",
      "Warning, aucun descripteur trouvé pour i = 6169\n",
      "Warning, aucun descripteur trouvé pour i = 6170\n",
      "Warning, aucun descripteur trouvé pour i = 6171\n",
      "Warning, aucun descripteur trouvé pour i = 6261\n",
      "Warning, aucun descripteur trouvé pour i = 6262\n",
      "Warning, aucun descripteur trouvé pour i = 6268\n",
      "Warning, aucun descripteur trouvé pour i = 6269\n",
      "Warning, aucun descripteur trouvé pour i = 6270\n",
      "Warning, aucun descripteur trouvé pour i = 6271\n",
      "Warning, aucun descripteur trouvé pour i = 6429\n",
      "Warning, aucun descripteur trouvé pour i = 6524\n",
      "Warning, aucun descripteur trouvé pour i = 6525\n",
      "Warning, aucun descripteur trouvé pour i = 6526\n",
      "Warning, aucun descripteur trouvé pour i = 6527\n",
      "Warning, aucun descripteur trouvé pour i = 6528\n",
      "Warning, aucun descripteur trouvé pour i = 6529\n",
      "Warning, aucun descripteur trouvé pour i = 6530\n",
      "Warning, aucun descripteur trouvé pour i = 6531\n",
      "Warning, aucun descripteur trouvé pour i = 6535\n",
      "Warning, aucun descripteur trouvé pour i = 6572\n",
      "Warning, aucun descripteur trouvé pour i = 6573\n",
      "Warning, aucun descripteur trouvé pour i = 6628\n",
      "Warning, aucun descripteur trouvé pour i = 6629\n",
      "Warning, aucun descripteur trouvé pour i = 6630\n",
      "Warning, aucun descripteur trouvé pour i = 6631\n",
      "Warning, aucun descripteur trouvé pour i = 6700\n",
      "Warning, aucun descripteur trouvé pour i = 6701\n",
      "Warning, aucun descripteur trouvé pour i = 6702\n",
      "Warning, aucun descripteur trouvé pour i = 6703\n",
      "Warning, aucun descripteur trouvé pour i = 6704\n",
      "Warning, aucun descripteur trouvé pour i = 6705\n",
      "Warning, aucun descripteur trouvé pour i = 6706\n",
      "Warning, aucun descripteur trouvé pour i = 6707\n",
      "Warning, aucun descripteur trouvé pour i = 6764\n",
      "Warning, aucun descripteur trouvé pour i = 6765\n",
      "Warning, aucun descripteur trouvé pour i = 6820\n",
      "Warning, aucun descripteur trouvé pour i = 6822\n",
      "Warning, aucun descripteur trouvé pour i = 6852\n",
      "Warning, aucun descripteur trouvé pour i = 6853\n",
      "Warning, aucun descripteur trouvé pour i = 6854\n",
      "Warning, aucun descripteur trouvé pour i = 6855\n",
      "Warning, aucun descripteur trouvé pour i = 6920\n",
      "Warning, aucun descripteur trouvé pour i = 6921\n",
      "Warning, aucun descripteur trouvé pour i = 6922\n",
      "Warning, aucun descripteur trouvé pour i = 6923\n",
      "Warning, aucun descripteur trouvé pour i = 6992\n",
      "Warning, aucun descripteur trouvé pour i = 6994\n",
      "Warning, aucun descripteur trouvé pour i = 7022\n",
      "Warning, aucun descripteur trouvé pour i = 7023\n",
      "Warning, aucun descripteur trouvé pour i = 7087\n",
      "Warning, aucun descripteur trouvé pour i = 7092\n",
      "Warning, aucun descripteur trouvé pour i = 7093\n",
      "Warning, aucun descripteur trouvé pour i = 7094\n",
      "Warning, aucun descripteur trouvé pour i = 7095\n",
      "Warning, aucun descripteur trouvé pour i = 7096\n",
      "Warning, aucun descripteur trouvé pour i = 7097\n",
      "Warning, aucun descripteur trouvé pour i = 7098\n",
      "Warning, aucun descripteur trouvé pour i = 7099\n",
      "Warning, aucun descripteur trouvé pour i = 7128\n",
      "Warning, aucun descripteur trouvé pour i = 7129\n",
      "Warning, aucun descripteur trouvé pour i = 7130\n",
      "Warning, aucun descripteur trouvé pour i = 7131\n",
      "(5779, 6400)\n",
      "(1445, 6400)\n",
      "bool\n"
     ]
    }
   ],
   "source": [
    "mandatory_n_keypoints = 25 # le nombre de keypoints détecté par image n'est pas garanti, il peut être moins -> padding de zéros\n",
    "orb = ORB(n_keypoints=mandatory_n_keypoints) # valeurs par défaut\n",
    "\n",
    "def ORB_extractor(patchs):\n",
    "    orb.detect_and_extract(patchs[0])\n",
    "\n",
    "    features = np.zeros(shape=(len(patchs),mandatory_n_keypoints*orb.descriptors.shape[1]), dtype=orb.descriptors.dtype)\n",
    "    \n",
    "    for i, patch in enumerate(patchs):\n",
    "        try:\n",
    "            orb.detect_and_extract(patch)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "        if orb.descriptors.shape[0] == 0:\n",
    "            print(f\"Warning, aucun descripteur trouvé pour i = {i}\")\n",
    "        if orb.descriptors.shape[0] == mandatory_n_keypoints:\n",
    "            features[i] = orb.descriptors.flatten()\n",
    "        else:\n",
    "        # obligatoirement plus bas (déjà cappé par le paramètre n_keypoints)\n",
    "            pad = np.zeros((1,(mandatory_n_keypoints - orb.descriptors.shape[0])*orb.descriptors.shape[1]),dtype=orb.descriptors.dtype)\n",
    "            features[i] = np.hstack([orb.descriptors.reshape((1,-1)), pad])\n",
    "\n",
    "    return features\n",
    "\n",
    "X_train_ORB, X_test_ORB = get_X_train_and_test_for_extractor(ORB_extractor)\n",
    "\n",
    "print(X_train_ORB.shape)\n",
    "print(X_test_ORB.shape)\n",
    "print(X_train_ORB.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f42995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5779, 6400)\n",
      "(1445, 6400)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "mandatory_n_keypoints = 50\n",
    "# le nombre de keypoints détecté par image n'est pas garanti, il peut être moins -> padding de zéros*\n",
    "# (par contre, il a l'air de détecter plus de keypoints qu'orb ?) (1 key point a 2 fois moins de données, donc je double la valeur finalement)\n",
    "\n",
    "sift = SIFT() # valeurs par défaut\n",
    "\n",
    "def SIFT_extractor(patchs):\n",
    "    sift.detect_and_extract(patchs[0])\n",
    "\n",
    "    features = np.zeros(shape=(len(patchs),mandatory_n_keypoints*sift.descriptors.shape[1]), dtype=sift.descriptors.dtype)\n",
    "    \n",
    "    for i, patch in enumerate(patchs):\n",
    "        try:\n",
    "            sift.detect_and_extract(patch)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "        if sift.descriptors.shape[0] == 0:\n",
    "            print(f\"Warning, aucun descripteur trouvé pour i = {i}\")\n",
    "        if sift.descriptors.shape[0] >= mandatory_n_keypoints:\n",
    "            features[i] = sift.descriptors[0:mandatory_n_keypoints, :].flatten()\n",
    "        else:\n",
    "            pad = np.zeros((1,(mandatory_n_keypoints - sift.descriptors.shape[0])*sift.descriptors.shape[1]),dtype=sift.descriptors.dtype)\n",
    "            features[i] = np.hstack([sift.descriptors.reshape((1,-1)), pad])\n",
    "\n",
    "    return features\n",
    "\n",
    "X_train_SIFT, X_test_SIFT = get_X_train_and_test_for_extractor(SIFT_extractor)\n",
    "\n",
    "print(X_train_SIFT.shape)\n",
    "print(X_test_SIFT.shape)\n",
    "print(X_train_SIFT.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef426c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5779, 55000)\n",
      "(1445, 55000)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# daisy renvoie des vecteurs de description de taille fixe pour des images de tailles fixes\n",
    "\n",
    "def DAISY_extractor(patchs):\n",
    "    first_features = daisy(patchs[0]) # valeurs par défaut\n",
    "\n",
    "    features = np.zeros(shape=(len(patchs),first_features.size), dtype=first_features.dtype)\n",
    "    \n",
    "    for i, patch in enumerate(patchs):\n",
    "        features[i] = daisy(patch).flatten()\n",
    "\n",
    "    return features\n",
    "\n",
    "X_train_DAISY, X_test_DAISY = get_X_train_and_test_for_extractor(DAISY_extractor)\n",
    "\n",
    "print(X_train_DAISY.shape)\n",
    "print(X_test_DAISY.shape) # 55000 valeurs pour une image !\n",
    "print(X_train_DAISY.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5888050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5779, 9216)\n",
      "(1445, 9216)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# lpb renvoie des vecteurs de description de taille fixe pour des images de tailles fixes\n",
    "\n",
    "# la fonction n'a pas de paramètres par défaut pour les 2 premiers params, j'ai copié ceux de l'exemple officiel : \n",
    "# https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-local-binary-pattern-py\n",
    "\n",
    "# settings for LBP\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "\n",
    "def LPB_extractor(patchs):\n",
    "    first_features = local_binary_pattern(patchs[0],n_points,radius) # les autres valeurs sont par défaut\n",
    "\n",
    "    features = np.zeros(shape=(len(patchs),first_features.size), dtype=first_features.dtype)\n",
    "    \n",
    "    for i, patch in enumerate(patchs):\n",
    "        features[i] = local_binary_pattern(patch,n_points,radius).flatten()\n",
    "\n",
    "    return features\n",
    "\n",
    "X_train_LPB, X_test_LPB = get_X_train_and_test_for_extractor(LPB_extractor)\n",
    "\n",
    "print(X_train_LPB.shape)\n",
    "print(X_test_LPB.shape)\n",
    "print(X_train_LPB.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784688dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5779, 9216)\n",
      "(1445, 9216)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "def PIXEL_extractor(patchs):\n",
    "    # vecteur de description = les pixels de l'image\n",
    "    features = np.zeros(shape=(len(patchs),patchs[0].size), dtype=patchs.dtype)\n",
    "    \n",
    "    for i, patch in enumerate(patchs):\n",
    "        features[i] = patch.flatten()\n",
    "\n",
    "    return features\n",
    "\n",
    "X_train_PIXEL, X_test_PIXEL = get_X_train_and_test_for_extractor(PIXEL_extractor)\n",
    "\n",
    "print(X_train_PIXEL.shape)\n",
    "print(X_test_PIXEL.shape)\n",
    "print(X_train_PIXEL.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee6306",
   "metadata": {},
   "source": [
    "## Construire les jeux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fb743c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains = [X_train_HOG, X_train_PIXEL, X_train_ORB, X_train_SIFT, X_train_DAISY, X_train_LPB]\n",
    "X_tests = [X_test_HOG, X_test_PIXEL, X_test_ORB, X_test_SIFT, X_test_DAISY, X_test_LPB]\n",
    "X_names = [\"HOG\", \"PIXEL\",\"ORB\",\"SIFT\",\"DAISY\",\"LPB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90893b80",
   "metadata": {},
   "source": [
    "#### Diviser le jeu\n",
    "\n",
    "TODO : peut-être une validation croisée (déjà implémentée par des bibliothèques, cf. TD6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099bdaf",
   "metadata": {},
   "source": [
    "## Choix du classifieur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae0856",
   "metadata": {},
   "source": [
    "Nous allons choisir le classifieur le plus efficace parmis un certain nombre de classifieurs + combinaison avec les extracteurs de features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a43691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def test_model(\n",
    "    name, model, X_train, y_train, X_test, y_test, X_name, df_resultat_clf\n",
    "):\n",
    "\n",
    "    print(f\"Testing {name} (x) {X_name} ...\")\n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    time_train = time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    time_pred = time.time() - start\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    error = (1 - accuracy) * 100\n",
    "    # Calculer le rappel et la précision\n",
    "    rappel = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1_score = 2 * (precision * rappel) / (precision + rappel)\n",
    "    avg_precision_score = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    df_resultat_clf = pd.concat(\n",
    "        [\n",
    "            df_resultat_clf,\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"model\": name,\n",
    "                        \"features\": X_name,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"error%\": error,\n",
    "                        \"rappel\": rappel,\n",
    "                        \"precision\": precision,\n",
    "                        \"f1_score\": f1_score,\n",
    "                        \"average_precision_score\": avg_precision_score,\n",
    "                        \"time_train\":time_train,\n",
    "                        \"time_pred\":time_pred,\n",
    "                    }\n",
    "                ]\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    return df_resultat_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c07dcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_dict():\n",
    "\n",
    "    models_dict = {}\n",
    "    # KNN\n",
    "    neighbors_list = [3, 25, 100, 250]\n",
    "    for neighbors in neighbors_list:\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "        models_dict[f\"KNN (k={neighbors})\"] = knn\n",
    "\n",
    "    # Decision Tree\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    models_dict[\"Decision Tree\"] = decision_tree\n",
    "\n",
    "    # Random Forest\n",
    "    estimators_list = [3, 25, 100, 250]\n",
    "    for estimators in estimators_list:\n",
    "        random_forest = RandomForestClassifier(n_estimators=estimators)\n",
    "        models_dict[f\"Random Forest (n_estimators={estimators})\"] = random_forest\n",
    "\n",
    "    # SVC\n",
    "    svc = SVC()\n",
    "    models_dict[\"SVC\"] = svc\n",
    "\n",
    "    # LinearSVC\n",
    "    linear_svc = LinearSVC()\n",
    "    models_dict[\"Linear SVC\"] = linear_svc\n",
    "\n",
    "    # SVC kernel\n",
    "    svc_kernel_list = [\"poly\", \"rbf\", \"sigmoid\"]\n",
    "    for kernel in svc_kernel_list:\n",
    "        svc_kernel = SVC(kernel=kernel)\n",
    "        models_dict[f\"SVC (kernel={kernel})\"] = svc_kernel\n",
    "\n",
    "    # Logistic Regression\n",
    "    iter_list = [25, 200, 400]\n",
    "    for n_iter in iter_list:\n",
    "        logistic_regression = LogisticRegression(max_iter=n_iter)\n",
    "        models_dict[f\"Logistic Regression (max_iter={n_iter})\"] = logistic_regression\n",
    "\n",
    "    # AdaBoost\n",
    "    estimators_list = [10, 25, 100]\n",
    "    for estimators in estimators_list:\n",
    "        ada_boost = AdaBoostClassifier(n_estimators=estimators)\n",
    "        models_dict[f\"AdaBoost (n_estimators={estimators})\"] = ada_boost\n",
    "\n",
    "    return models_dict\n",
    "\n",
    "    # Gradient Boosting\n",
    "    learning_rate_list = [0.01, 0.2, 0.5]\n",
    "    for learning_rate in learning_rate_list:\n",
    "        gradient_boosting = GradientBoostingClassifier(learning_rate=learning_rate)\n",
    "        models_dict[f\"Gradient Boosting (learning_rate={learning_rate})\"] = (\n",
    "            gradient_boosting\n",
    "        )\n",
    "    return models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aae00bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing KNN (k=3) (x) HOG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adrien\\AppData\\Local\\Temp\\ipykernel_21764\\335908396.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_resultat_clf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing KNN (k=3) (x) PIXEL ...\n",
      "Testing KNN (k=3) (x) ORB ...\n",
      "Testing KNN (k=3) (x) SIFT ...\n",
      "Testing KNN (k=3) (x) DAISY ...\n",
      "Testing KNN (k=3) (x) LPB ...\n",
      "Testing KNN (k=25) (x) HOG ...\n",
      "Testing KNN (k=25) (x) PIXEL ...\n",
      "Testing KNN (k=25) (x) ORB ...\n",
      "Testing KNN (k=25) (x) SIFT ...\n",
      "Testing KNN (k=25) (x) DAISY ...\n",
      "Testing KNN (k=25) (x) LPB ...\n",
      "Testing KNN (k=100) (x) HOG ...\n",
      "Testing KNN (k=100) (x) PIXEL ...\n",
      "Testing KNN (k=100) (x) ORB ...\n",
      "Testing KNN (k=100) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Adrien\\AppData\\Local\\Temp\\ipykernel_21764\\335908396.py:22: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2 * (precision * rappel) / (precision + rappel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing KNN (k=100) (x) DAISY ...\n",
      "Testing KNN (k=100) (x) LPB ...\n",
      "Testing KNN (k=250) (x) HOG ...\n",
      "Testing KNN (k=250) (x) PIXEL ...\n",
      "Testing KNN (k=250) (x) ORB ...\n",
      "Testing KNN (k=250) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Adrien\\AppData\\Local\\Temp\\ipykernel_21764\\335908396.py:22: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2 * (precision * rappel) / (precision + rappel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing KNN (k=250) (x) DAISY ...\n",
      "Testing KNN (k=250) (x) LPB ...\n",
      "Testing Decision Tree (x) HOG ...\n",
      "Testing Decision Tree (x) PIXEL ...\n",
      "Testing Decision Tree (x) ORB ...\n",
      "Testing Decision Tree (x) SIFT ...\n",
      "Testing Decision Tree (x) DAISY ...\n",
      "Testing Decision Tree (x) LPB ...\n",
      "Testing Random Forest (n_estimators=3) (x) HOG ...\n",
      "Testing Random Forest (n_estimators=3) (x) PIXEL ...\n",
      "Testing Random Forest (n_estimators=3) (x) ORB ...\n",
      "Testing Random Forest (n_estimators=3) (x) SIFT ...\n",
      "Testing Random Forest (n_estimators=3) (x) DAISY ...\n",
      "Testing Random Forest (n_estimators=3) (x) LPB ...\n",
      "Testing Random Forest (n_estimators=25) (x) HOG ...\n",
      "Testing Random Forest (n_estimators=25) (x) PIXEL ...\n",
      "Testing Random Forest (n_estimators=25) (x) ORB ...\n",
      "Testing Random Forest (n_estimators=25) (x) SIFT ...\n",
      "Testing Random Forest (n_estimators=25) (x) DAISY ...\n",
      "Testing Random Forest (n_estimators=25) (x) LPB ...\n",
      "Testing Random Forest (n_estimators=100) (x) HOG ...\n",
      "Testing Random Forest (n_estimators=100) (x) PIXEL ...\n",
      "Testing Random Forest (n_estimators=100) (x) ORB ...\n",
      "Testing Random Forest (n_estimators=100) (x) SIFT ...\n",
      "Testing Random Forest (n_estimators=100) (x) DAISY ...\n",
      "Testing Random Forest (n_estimators=100) (x) LPB ...\n",
      "Testing Random Forest (n_estimators=250) (x) HOG ...\n",
      "Testing Random Forest (n_estimators=250) (x) PIXEL ...\n",
      "Testing Random Forest (n_estimators=250) (x) ORB ...\n",
      "Testing Random Forest (n_estimators=250) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Adrien\\AppData\\Local\\Temp\\ipykernel_21764\\335908396.py:22: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1_score = 2 * (precision * rappel) / (precision + rappel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Random Forest (n_estimators=250) (x) DAISY ...\n",
      "Testing Random Forest (n_estimators=250) (x) LPB ...\n",
      "Testing SVC (x) HOG ...\n",
      "Testing SVC (x) PIXEL ...\n",
      "Testing SVC (x) ORB ...\n",
      "Testing SVC (x) SIFT ...\n",
      "Testing SVC (x) DAISY ...\n",
      "Testing SVC (x) LPB ...\n",
      "Testing Linear SVC (x) HOG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear SVC (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear SVC (x) ORB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear SVC (x) SIFT ...\n",
      "Testing Linear SVC (x) DAISY ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear SVC (x) LPB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SVC (kernel=poly) (x) HOG ...\n",
      "Testing SVC (kernel=poly) (x) PIXEL ...\n",
      "Testing SVC (kernel=poly) (x) ORB ...\n",
      "Testing SVC (kernel=poly) (x) SIFT ...\n",
      "Testing SVC (kernel=poly) (x) DAISY ...\n",
      "Testing SVC (kernel=poly) (x) LPB ...\n",
      "Testing SVC (kernel=rbf) (x) HOG ...\n",
      "Testing SVC (kernel=rbf) (x) PIXEL ...\n",
      "Testing SVC (kernel=rbf) (x) ORB ...\n",
      "Testing SVC (kernel=rbf) (x) SIFT ...\n",
      "Testing SVC (kernel=rbf) (x) DAISY ...\n",
      "Testing SVC (kernel=rbf) (x) LPB ...\n",
      "Testing SVC (kernel=sigmoid) (x) HOG ...\n",
      "Testing SVC (kernel=sigmoid) (x) PIXEL ...\n",
      "Testing SVC (kernel=sigmoid) (x) ORB ...\n",
      "Testing SVC (kernel=sigmoid) (x) SIFT ...\n",
      "Testing SVC (kernel=sigmoid) (x) DAISY ...\n",
      "Testing SVC (kernel=sigmoid) (x) LPB ...\n",
      "Testing Logistic Regression (max_iter=25) (x) HOG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=25) (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=25) (x) ORB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=25) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=25) (x) DAISY ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=25) (x) LPB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=200) (x) HOG ...\n",
      "Testing Logistic Regression (max_iter=200) (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=200) (x) ORB ...\n",
      "Testing Logistic Regression (max_iter=200) (x) SIFT ...\n",
      "Testing Logistic Regression (max_iter=200) (x) DAISY ...\n",
      "Testing Logistic Regression (max_iter=200) (x) LPB ...\n",
      "Testing Logistic Regression (max_iter=400) (x) HOG ...\n",
      "Testing Logistic Regression (max_iter=400) (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression (max_iter=400) (x) ORB ...\n",
      "Testing Logistic Regression (max_iter=400) (x) SIFT ...\n",
      "Testing Logistic Regression (max_iter=400) (x) DAISY ...\n",
      "Testing Logistic Regression (max_iter=400) (x) LPB ...\n",
      "Testing AdaBoost (n_estimators=10) (x) HOG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=10) (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=10) (x) ORB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=10) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=10) (x) DAISY ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=10) (x) LPB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=25) (x) HOG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=25) (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=25) (x) ORB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=25) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=25) (x) DAISY ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=25) (x) LPB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=100) (x) HOG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=100) (x) PIXEL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=100) (x) ORB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=100) (x) SIFT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=100) (x) DAISY ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AdaBoost (n_estimators=100) (x) LPB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dossier_perso\\Projets\\Prog\\SY32_detection_ecocup\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 model features  accuracy     error%  \\\n",
      "66                   SVC (kernel=poly)      HOG  0.986851   1.314879   \n",
      "70                   SVC (kernel=poly)    DAISY  0.981315   1.868512   \n",
      "96  Logistic Regression (max_iter=400)      HOG  0.980623   1.937716   \n",
      "90  Logistic Regression (max_iter=200)      HOG  0.980623   1.937716   \n",
      "72                    SVC (kernel=rbf)      HOG  0.979931   2.006920   \n",
      "..                                 ...      ...       ...        ...   \n",
      "62                          Linear SVC      ORB  0.787543  21.245675   \n",
      "27                       Decision Tree     SIFT  0.773702  22.629758   \n",
      "26                       Decision Tree      ORB  0.759862  24.013841   \n",
      "83                SVC (kernel=sigmoid)      LPB  0.745329  25.467128   \n",
      "79                SVC (kernel=sigmoid)    PIXEL  0.669204  33.079585   \n",
      "\n",
      "      rappel  precision  f1_score  average_precision_score  time_train  \\\n",
      "66  0.936508   0.987448  0.961303                 0.935825   22.418278   \n",
      "70  0.924603   0.966805  0.945233                 0.907060  108.014973   \n",
      "96  0.920635   0.966667  0.943089                 0.903788    0.687378   \n",
      "90  0.920635   0.966667  0.943089                 0.903788    0.700054   \n",
      "72  0.896825   0.986900  0.939709                 0.903070   24.489752   \n",
      "..       ...        ...       ...                      ...         ...   \n",
      "62  0.341270   0.378855  0.359081                 0.244171    9.568382   \n",
      "27  0.361111   0.354086  0.357564                 0.239283   26.496617   \n",
      "26  0.361111   0.328520  0.344045                 0.230051    3.152055   \n",
      "83  0.166667   0.210000  0.185841                 0.180329   29.875241   \n",
      "79  0.051587   0.051587  0.051587                 0.168059   32.109143   \n",
      "\n",
      "    time_pred  \n",
      "66   5.195680  \n",
      "70  24.313498  \n",
      "96   0.003687  \n",
      "90   0.012753  \n",
      "72   9.351647  \n",
      "..        ...  \n",
      "62   0.012090  \n",
      "27   0.005170  \n",
      "26   0.008970  \n",
      "83   7.107190  \n",
      "79   7.756485  \n",
      "\n",
      "[120 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_resultat_clf = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"features\",\n",
    "        \"accuracy\",\n",
    "        \"error%\",\n",
    "        \"rappel\",\n",
    "        \"precision\",\n",
    "        \"f1_score\",\n",
    "        \"average_precision_score\",\n",
    "        \"time_train\",\n",
    "        \"time_pred\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "models_dict = get_models_dict()\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    for X_train, X_test, X_name in zip(X_trains, X_tests, X_names):\n",
    "        df_resultat_clf = test_model(name, model, X_train, y_train, X_test, y_test, X_name, df_resultat_clf)\n",
    "\n",
    "df_resultat_clf = df_resultat_clf.sort_values(by=\"error%\")\n",
    "print(df_resultat_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb69e912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error%</th>\n",
       "      <th>rappel</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>average_precision_score</th>\n",
       "      <th>time_train</th>\n",
       "      <th>time_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SVC (kernel=poly)</td>\n",
       "      <td>HOG</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>1.314879</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.961303</td>\n",
       "      <td>0.935825</td>\n",
       "      <td>22.418278</td>\n",
       "      <td>5.195680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>SVC (kernel=poly)</td>\n",
       "      <td>DAISY</td>\n",
       "      <td>0.981315</td>\n",
       "      <td>1.868512</td>\n",
       "      <td>0.924603</td>\n",
       "      <td>0.966805</td>\n",
       "      <td>0.945233</td>\n",
       "      <td>0.907060</td>\n",
       "      <td>108.014973</td>\n",
       "      <td>24.313498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Logistic Regression (max_iter=400)</td>\n",
       "      <td>HOG</td>\n",
       "      <td>0.980623</td>\n",
       "      <td>1.937716</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.903788</td>\n",
       "      <td>0.687378</td>\n",
       "      <td>0.003687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Logistic Regression (max_iter=200)</td>\n",
       "      <td>HOG</td>\n",
       "      <td>0.980623</td>\n",
       "      <td>1.937716</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.903788</td>\n",
       "      <td>0.700054</td>\n",
       "      <td>0.012753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SVC (kernel=rbf)</td>\n",
       "      <td>HOG</td>\n",
       "      <td>0.979931</td>\n",
       "      <td>2.006920</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.939709</td>\n",
       "      <td>0.903070</td>\n",
       "      <td>24.489752</td>\n",
       "      <td>9.351647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model features  accuracy    error%    rappel  \\\n",
       "66                   SVC (kernel=poly)      HOG  0.986851  1.314879  0.936508   \n",
       "70                   SVC (kernel=poly)    DAISY  0.981315  1.868512  0.924603   \n",
       "96  Logistic Regression (max_iter=400)      HOG  0.980623  1.937716  0.920635   \n",
       "90  Logistic Regression (max_iter=200)      HOG  0.980623  1.937716  0.920635   \n",
       "72                    SVC (kernel=rbf)      HOG  0.979931  2.006920  0.896825   \n",
       "\n",
       "    precision  f1_score  average_precision_score  time_train  time_pred  \n",
       "66   0.987448  0.961303                 0.935825   22.418278   5.195680  \n",
       "70   0.966805  0.945233                 0.907060  108.014973  24.313498  \n",
       "96   0.966667  0.943089                 0.903788    0.687378   0.003687  \n",
       "90   0.966667  0.943089                 0.903788    0.700054   0.012753  \n",
       "72   0.986900  0.939709                 0.903070   24.489752   9.351647  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultat_clf.head() # attention, il y a des warnings dans l'output, ça change peut-être des valeurs à pas mal interpréter ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Accuracy:\n",
      "                                 model  accuracy\n",
      "66                   SVC (kernel=poly)  0.986851\n",
      "70                   SVC (kernel=poly)  0.981315\n",
      "96  Logistic Regression (max_iter=400)  0.980623\n",
      "\n",
      "Top 3 Rappel:\n",
      "                                 model    rappel\n",
      "66                   SVC (kernel=poly)  0.936508\n",
      "70                   SVC (kernel=poly)  0.924603\n",
      "96  Logistic Regression (max_iter=400)  0.920635\n",
      "\n",
      "Top 3 Précision:\n",
      "                               model  precision\n",
      "48  Random Forest (n_estimators=250)        1.0\n",
      "52  Random Forest (n_estimators=250)        1.0\n",
      "46  Random Forest (n_estimators=100)        1.0\n",
      "\n",
      "Top 3 F1 Score:\n",
      "                                 model  f1_score\n",
      "66                   SVC (kernel=poly)  0.961303\n",
      "70                   SVC (kernel=poly)  0.945233\n",
      "96  Logistic Regression (max_iter=400)  0.943089\n",
      "\n",
      "Top 3 Average Precision Score:\n",
      "                                 model  average_precision_score\n",
      "66                   SVC (kernel=poly)                 0.935825\n",
      "70                   SVC (kernel=poly)                 0.907060\n",
      "96  Logistic Regression (max_iter=400)                 0.903788\n"
     ]
    }
   ],
   "source": [
    "## Affichons les 3 meilleurs résultats pour chaque score\n",
    "# accuracy\n",
    "top_accuracy = df_resultat_clf.nlargest(3, \"accuracy\")\n",
    "print(\"Top 3 Accuracy:\")\n",
    "print(top_accuracy[[\"model\",\"features\", \"accuracy\"]])\n",
    "\n",
    "# rappel\n",
    "top_recall = df_resultat_clf.nlargest(3, \"rappel\")\n",
    "print(\"\\nTop 3 Rappel:\")\n",
    "print(top_recall[[\"model\",\"features\", \"rappel\"]])\n",
    "\n",
    "# précision\n",
    "top_precision = df_resultat_clf.nlargest(3, \"precision\")\n",
    "print(\"\\nTop 3 Précision:\")\n",
    "print(top_precision[[\"model\",\"features\", \"precision\"]])\n",
    "\n",
    "# f1_score\n",
    "top_f1_score = df_resultat_clf.nlargest(3, \"f1_score\")\n",
    "print(\"\\nTop 3 F1 Score:\")\n",
    "print(top_f1_score[[\"model\",\"features\", \"f1_score\"]])\n",
    "\n",
    "# average_precision_score\n",
    "top_avg_precision = df_resultat_clf.nlargest(3, \"average_precision_score\")\n",
    "print(\"\\nTop 3 Average Precision Score:\")\n",
    "print(top_avg_precision[[\"model\",\"features\", \"average_precision_score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer le dataframe\n",
    "df_resultat_clf.to_csv(\"resultats_classification.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
