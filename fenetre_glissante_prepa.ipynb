{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b34eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab01872",
   "metadata": {},
   "source": [
    "Chargement des données d'entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f956a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données des patchs normalisés\n",
    "pos_patch_fs = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(os.path.join(\"local_data\", \"4_normalized_patches\", \"pos\"))\n",
    "    if f.endswith(\".jpg\")\n",
    "]\n",
    "neg_patch_fs = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(os.path.join(\"local_data\", \"4_normalized_patches\", \"neg\"))\n",
    "    if f.endswith(\".jpg\")\n",
    "]\n",
    "\n",
    "pos_patchs = {}\n",
    "neg_patchs = {}\n",
    "\n",
    "for f in pos_patch_fs:\n",
    "    try:\n",
    "        patch = plt.imread(\n",
    "            os.path.join(\"local_data\", \"4_normalized_patches\", \"pos\", f\"{f}.jpg\")\n",
    "        )\n",
    "        pos_patchs[f] = patch[\n",
    "            :, :, 0\n",
    "        ]  # le channel grayscale est dupliqué sur les 3 chanaux RGB (on en isole 1)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "for f in neg_patch_fs:\n",
    "    try:\n",
    "        patch = plt.imread(\n",
    "            os.path.join(\"local_data\", \"4_normalized_patches\", \"neg\", f\"{f}.jpg\")\n",
    "        )\n",
    "        neg_patchs[f] = patch[\n",
    "            :, :, 0\n",
    "        ]  # le channel grayscale est dupliqué sur les 3 chanaux RGB (on en isole 1)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "nb_patchs_tot = len(pos_patchs) + len(neg_patchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce2fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des images ! (on utilse une partie du set d'entraînement comme validation aussi)\n",
    "# Elles sont grayscale directement\n",
    "pos_img_fs = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(\n",
    "        os.path.join(\"local_data\", \"1_data_filtered\", \"train\", \"images\", \"pos\")\n",
    "    )\n",
    "    if f.endswith(\".jpg\")\n",
    "]\n",
    "neg_img_fs = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(\n",
    "        os.path.join(\"local_data\", \"1_data_filtered\", \"train\", \"images\", \"neg\")\n",
    "    )\n",
    "    if f.endswith(\".jpg\")\n",
    "]\n",
    "\n",
    "pos_imgs = {}\n",
    "pos_img_names = []\n",
    "neg_imgs = {}\n",
    "neg_img_names = []\n",
    "\n",
    "for f in pos_img_fs:\n",
    "    try:\n",
    "        img = plt.imread(\n",
    "            os.path.join(\n",
    "                \"local_data\", \"1_data_filtered\", \"train\", \"images\", \"pos\", f\"{f}.jpg\"\n",
    "            )\n",
    "        )\n",
    "        pos_imgs[f] = rgb2gray(img)\n",
    "        pos_img_names.append(f)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "for f in neg_img_fs:\n",
    "    try:\n",
    "        img = plt.imread(\n",
    "            os.path.join(\n",
    "                \"local_data\", \"1_data_filtered\", \"train\", \"images\", \"neg\", f\"{f}.jpg\"\n",
    "            )\n",
    "        )\n",
    "        neg_imgs[f] = rgb2gray(img)\n",
    "        neg_img_names.append(f)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "nb_imgs_tot = len(pos_imgs) + len(neg_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22cbd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pos/neg :  313 144\n",
      "tests pos/neg :  63 29\n",
      "exemple d'image prise pour le test :  pos/0134.jpg\n",
      "exemple d'image prise pour le test :  neg/0024.jpg\n"
     ]
    }
   ],
   "source": [
    "# Selection des images d'entraînement et des images de validation (test) parmi celles du dossier train\n",
    "train_part = 80 / 100\n",
    "\n",
    "# Mélange des indices, pour que les données soient mélangées \"en même temps\"\n",
    "# Et surtout, on fait en sorte de filtrer les patchs d'entraînement du classifieur de sorte qu'il n'y en ait aucun appartenant aux images de test !\n",
    "rng = np.random.default_rng(seed=0)\n",
    "idx_pos = np.arange(len(pos_imgs))\n",
    "idx_neg = np.arange(len(neg_imgs))\n",
    "rng.shuffle(idx_pos)\n",
    "rng.shuffle(idx_neg)\n",
    "\n",
    "pos_img_names_shuffled = np.array(pos_img_names)[idx_pos]\n",
    "\n",
    "neg_img_names_shuffled = np.array(neg_img_names)[idx_neg]\n",
    "\n",
    "cutoff_pos = int(train_part * len(pos_imgs))\n",
    "pos_img_test_names = pos_img_names_shuffled[cutoff_pos:]\n",
    "\n",
    "cutoff_neg = int(train_part * len(neg_imgs))\n",
    "neg_img_test_names = neg_img_names_shuffled[cutoff_neg:]\n",
    "\n",
    "pos_img_test = [pos_imgs[f] for f in pos_img_test_names]\n",
    "neg_img_test = [neg_imgs[f] for f in neg_img_test_names]\n",
    "\n",
    "imgs_test = (\n",
    "    pos_img_test + neg_img_test\n",
    ")  # ça nous permet aussi de simplifier notre vérification, on sait que toutes les images positives sont au début\n",
    "print(\"total pos/neg : \", len(pos_imgs), len(neg_imgs))\n",
    "print(\"tests pos/neg : \", len(pos_img_test), len(neg_img_test))\n",
    "print(\"exemple d'image prise pour le test : \", f\"pos/{pos_img_test_names[0]}.jpg\")\n",
    "print(\"exemple d'image prise pour le test : \", f\"neg/{neg_img_test_names[0]}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3a4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204 6020\n",
      "948 4856\n",
      "(5804, 128, 72)\n",
      "(5804,)\n"
     ]
    }
   ],
   "source": [
    "# Filtre : les patchs servant à l'entraînement sont tous ceux qui n'appartiennent pas aux images de tests\n",
    "\n",
    "# test_string = \"0277_00\"\n",
    "# print(test_string[:4]) # \"0277\"\n",
    "\n",
    "pos_patchs_train = np.array(\n",
    "    [pos_patchs[f] for f in pos_patchs.keys() if f[:4] not in pos_img_test_names]\n",
    ")\n",
    "neg_patchs_train = np.array(\n",
    "    [neg_patchs[f] for f in neg_patchs.keys() if f[:4] not in neg_img_test_names]\n",
    ")\n",
    "\n",
    "print(len(pos_patchs), len(neg_patchs))\n",
    "print(len(pos_patchs_train), len(neg_patchs_train))\n",
    "\n",
    "y_train = np.hstack(\n",
    "    [np.ones((1, len(pos_patchs_train))), np.zeros((1, len(neg_patchs_train)))]\n",
    ").flatten()\n",
    "\n",
    "patchs_train = np.vstack([pos_patchs_train, neg_patchs_train])\n",
    "print(patchs_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfb5e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5804, 7938)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Extraction des features sur les patchs d'entraînement\n",
    "# TODO : y placer les paramètres optimisés\n",
    "\n",
    "\n",
    "def HOG_extractor(patchs):\n",
    "    first_features = hog(patchs[0])  # valeurs par défaut\n",
    "    features = np.zeros(\n",
    "        shape=(len(patchs), first_features.shape[0]), dtype=first_features.dtype\n",
    "    )\n",
    "    for i, patch in enumerate(patchs):\n",
    "        features[i] = hog(patch)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "X_train = HOG_extractor(patchs_train)\n",
    "print(X_train.shape)\n",
    "print(X_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be379f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "# TODO : y placer les paramètres optimisés\n",
    "\n",
    "clf = SVC(kernel=\"poly\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379bb41",
   "metadata": {},
   "source": [
    "Autres trucs utiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf8c7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34117647, 0.4745098 , 0.40784314, ..., 0.43921569, 0.33333333,\n",
       "        0.52156863],\n",
       "       [0.34117647, 0.41960784, 0.35686275, ..., 0.43529412, 0.41176471,\n",
       "        0.39607843],\n",
       "       [0.34901961, 0.37647059, 0.38039216, ..., 0.35686275, 0.38039216,\n",
       "        0.27843137],\n",
       "       ...,\n",
       "       [0.31372549, 0.33333333, 0.36078431, ..., 0.28627451, 0.4       ,\n",
       "        0.30588235],\n",
       "       [0.30980392, 0.34117647, 0.37647059, ..., 0.36078431, 0.19607843,\n",
       "        0.20392157],\n",
       "       [0.30588235, 0.34509804, 0.38039216, ..., 0.21960784, 0.22745098,\n",
       "        0.35294118]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from functools import partial\n",
    "\n",
    "module_name = \"local_data.4_normalized_patches.normalizer\"\n",
    "normalizer = importlib.import_module(module_name)\n",
    "\n",
    "# test de si la fonction marche bien ici\n",
    "target_shape = normalizer.get_target_shape()\n",
    "normalize_patch = partial(normalizer.normalize_patch, target_shape)\n",
    "__patch = patchs_train[0]\n",
    "normalize_patch(__patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aff4b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42758620689655175\n",
      "0.9832214765100671\n",
      "0.5725892334813942\n",
      "107\n",
      "2635\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "with open(\n",
    "    os.path.join(\"local_data\", \"4_normalized_patches\", \"stats.txt\"),\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\",\n",
    ") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or \"=\" not in line:\n",
    "            continue\n",
    "\n",
    "        key, value = line.split(\"=\", 1)\n",
    "\n",
    "        try:\n",
    "            val = float(value)\n",
    "            if val.is_integer():\n",
    "                val = int(val)\n",
    "            stats[key] = val\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "# Extraction dans des variables individuelles (optionnel)\n",
    "min_ratio = stats.get(\"min_ratio\")\n",
    "max_ratio = stats.get(\"max_ratio\")\n",
    "moy_ratio = stats.get(\"moy_ratio\")\n",
    "min_scale = stats.get(\"min_scale\")\n",
    "max_scale = stats.get(\"max_scale\")\n",
    "\n",
    "print(min_ratio)\n",
    "print(max_ratio)\n",
    "print(moy_ratio)\n",
    "print(min_scale)\n",
    "print(max_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfbbd8f",
   "metadata": {},
   "source": [
    "Toutes les variables que tu peux utiliser pour tester ta détection dans la suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81be678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.HOG_extractor(patchs)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Trucs globaux\n",
    "\n",
    "imgs_test  # liste python des images de test (qui sont déjà grayscale, chaque image est une numpy array 2D)\n",
    "# composée (DANS L'ORDRE !) de 63 images positives (on sait qu'il y a au moins une ecocup) + 29 images négatives\n",
    "\n",
    "clf  # Le fameux classifieur SVC(kernel=\"poly\") entraîné avec les features extraites grâce à un HOG sur des patchs normalisés\n",
    "# appartenant seulement aux images d'entraînement, c'est-à-dire que le classifieur \"n'a jamais vue\" les images de test, même en partie\n",
    "\n",
    "\n",
    "### Limites de formes des fenêtres de découpe\n",
    "\n",
    "min_scale  # facteur de scale minimum mesuré dans les bbox d'annotations sur les images positives (c'est-à-dire la longueur du rectangle)\n",
    "max_scale  # facteur de scale max\n",
    "\n",
    "min_ratio  # ratio minimum mesuré (rapport entre largeur/hauteur), un ratio petit fait que la fenêtre apparâit plus \"carrée\"\n",
    "max_ratio  # ratio maximum mesuré\n",
    "\n",
    "# Exemple pour obtenir les dimensions de la plus grande fenêtre de test :\n",
    "# (max_ratio*max_scale, max_scale) : (width, height), la fenêtre apparaît comme un rectangle \"debout\"\n",
    "# il faudrait aussi tester le cas inverse :\n",
    "# (max_scale, max_ratio*max_scale) : (width, height), la fenêtre apparaît comme un rectangle \"allongé\"\n",
    "\n",
    "\n",
    "### Traitement des patchs\n",
    "normalize_patch  # fonction qui prend une fenêtre découpée d'une image, et la normalise dans un \"patch normalisé\"\n",
    "HOG_extractor  # fonction qui prend une liste ou array de patchs normalisés et extrait les features (pour fabriquer X_test pour soumission à la prédiction du classifieur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a830a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input image is too small given the values of pixels_per_cell and cells_per_block. It should have at least: 24 rows and 24 cols.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect_ecocup\n\u001b[32m      3\u001b[39m img = imgs_test[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# on prend la première image de test\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m detections = \u001b[43mdetect_ecocup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHOG_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Affichage des détections\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisual\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_boxes_on_image\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\engel\\OneDrive\\Documents\\Travail\\SY32\\projet\\code_projet\\SY32_detection_ecocup\\utils\\detection.py:196\u001b[39m, in \u001b[36mdetect_ecocup\u001b[39m\u001b[34m(img, classifier, features_func)\u001b[39m\n\u001b[32m    188\u001b[39m img_parts_valid = [\n\u001b[32m    189\u001b[39m     (img_part, idx)\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, img_part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(img_parts)\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img_part \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img_part.size != \u001b[32m0\u001b[39m\n\u001b[32m    192\u001b[39m ]\n\u001b[32m    193\u001b[39m normalized_parts = [\n\u001b[32m    194\u001b[39m     normalize_patch(img_part) \u001b[38;5;28;01mfor\u001b[39;00m img_part, _ \u001b[38;5;129;01min\u001b[39;00m img_parts_valid\n\u001b[32m    195\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m features = \u001b[43m[\u001b[49m\u001b[43mfeatures_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_part\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg_part\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnormalized_parts\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    198\u001b[39m preds = classifier.predict(features)\n\u001b[32m    199\u001b[39m probas = classifier.predict_proba(features)[:, \u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# proba classe \"gobelet\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\engel\\OneDrive\\Documents\\Travail\\SY32\\projet\\code_projet\\SY32_detection_ecocup\\utils\\detection.py:196\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    188\u001b[39m img_parts_valid = [\n\u001b[32m    189\u001b[39m     (img_part, idx)\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, img_part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(img_parts)\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img_part \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img_part.size != \u001b[32m0\u001b[39m\n\u001b[32m    192\u001b[39m ]\n\u001b[32m    193\u001b[39m normalized_parts = [\n\u001b[32m    194\u001b[39m     normalize_patch(img_part) \u001b[38;5;28;01mfor\u001b[39;00m img_part, _ \u001b[38;5;129;01min\u001b[39;00m img_parts_valid\n\u001b[32m    195\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m features = [\u001b[43mfeatures_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_part\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img_part \u001b[38;5;129;01min\u001b[39;00m normalized_parts]\n\u001b[32m    198\u001b[39m preds = classifier.predict(features)\n\u001b[32m    199\u001b[39m probas = classifier.predict_proba(features)[:, \u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# proba classe \"gobelet\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mHOG_extractor\u001b[39m\u001b[34m(patchs)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mHOG_extractor\u001b[39m(patchs):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     first_features = \u001b[43mhog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatchs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# valeurs par défaut\u001b[39;00m\n\u001b[32m      7\u001b[39m     features = np.zeros(\n\u001b[32m      8\u001b[39m         shape=(\u001b[38;5;28mlen\u001b[39m(patchs), first_features.shape[\u001b[32m0\u001b[39m]), dtype=first_features.dtype\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, patch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(patchs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\engel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\_shared\\utils.py:445\u001b[39m, in \u001b[36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    442\u001b[39m channel_axis = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mchannel_axis\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isscalar(channel_axis):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\engel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\feature\\_hog.py:314\u001b[39m, in \u001b[36mhog\u001b[39m\u001b[34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, channel_axis)\u001b[39m\n\u001b[32m    312\u001b[39m     min_row = b_row * c_row\n\u001b[32m    313\u001b[39m     min_col = b_col * c_col\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    315\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThe input image is too small given the values of \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    316\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpixels_per_cell and cells_per_block. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    317\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mIt should have at least: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_row\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cols.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    319\u001b[39m     )\n\u001b[32m    320\u001b[39m normalized_blocks = np.zeros(\n\u001b[32m    321\u001b[39m     (n_blocks_row, n_blocks_col, b_row, b_col, orientations), dtype=float_dtype\n\u001b[32m    322\u001b[39m )\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_blocks_row):\n",
      "\u001b[31mValueError\u001b[39m: The input image is too small given the values of pixels_per_cell and cells_per_block. It should have at least: 24 rows and 24 cols."
     ]
    }
   ],
   "source": [
    "from utils.detection import detect_ecocup\n",
    "\n",
    "img = imgs_test[0]  # on prend la première image de test\n",
    "detections = detect_ecocup(img, clf, HOG_extractor)\n",
    "\n",
    "# Affichage des détections\n",
    "from utils.visual import draw_boxes_on_image\n",
    "\n",
    "draw_boxes_on_image(img, detections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
